\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Research Questions}{3}{section.1.1}%
\contentsline {section}{\numberline {1.2}Structure of the Thesis}{5}{section.1.2}%
\contentsline {chapter}{\numberline {2}Background}{7}{chapter.2}%
\contentsline {section}{\numberline {2.1}Product Description in Online Retail}{7}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Elements of an Effective Product Description}{8}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Automatic Product Description Generation}{10}{subsection.2.1.2}%
\contentsline {section}{\numberline {2.2}Natural Language Processing}{11}{section.2.2}%
\contentsline {section}{\numberline {2.3}Large Language Models}{11}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Text Generation Task with Large Language Models}{12}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Transformers}{12}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}BLOOM: A 176B-Parameter Open-Access Multilingual Language Model}{14}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}Transfer learning}{15}{subsection.2.3.4}%
\contentsline {subsection}{\numberline {2.3.5}BLOOM-CLP German}{16}{subsection.2.3.5}%
\contentsline {subsection}{\numberline {2.3.6}BERT: Bidirectional Encoder Representations from Transformers}{16}{subsection.2.3.6}%
\contentsline {subsection}{\numberline {2.3.7}GPT2}{17}{subsection.2.3.7}%
\contentsline {subsubsection}{\nonumberline GPT2-wechsel-german}{17}{subsubsection*.8}%
\contentsline {subsection}{\numberline {2.3.8}Mistral 7B}{18}{subsection.2.3.8}%
\contentsline {subsubsection}{\nonumberline EM German}{18}{subsubsection*.10}%
\contentsline {section}{\numberline {2.4}Prompts in LLMs}{19}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Prompt Engineering}{19}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Zero/one/few-shot prompting}{20}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Challanges}{21}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Evaluating Text Generated by LLMs}{21}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}Text Generation with LLMs in German Language}{22}{subsection.2.5.2}%
\contentsline {chapter}{\numberline {3}Methods}{24}{chapter.3}%
\contentsline {section}{\numberline {3.1}Dataset}{25}{section.3.1}%
\contentsline {section}{\numberline {3.2}Pre-processing}{29}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Category Description}{29}{subsection.3.2.1}%
\contentsline {subsubsection}{\nonumberline Translation}{30}{subsubsection*.15}%
\contentsline {subsection}{\numberline {3.2.2}Shots}{30}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}Description Generation}{32}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Prompt}{32}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Text Generation}{34}{subsection.3.3.2}%
\contentsline {section}{\numberline {3.4}Post-processing}{35}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Remove Possible Hallucination}{36}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Rewriting}{36}{subsection.3.4.2}%
\contentsline {section}{\numberline {3.5}Evaluation}{37}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Readability Scores}{37}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Class Classification metric}{39}{subsection.3.5.2}%
\contentsline {subsubsection}{\nonumberline Class Classification}{39}{subsubsection*.17}%
\contentsline {subsubsection}{\nonumberline Comparing the 2 Category}{39}{subsubsection*.19}%
\contentsline {subsection}{\numberline {3.5.3}Bloom based coherence metric}{40}{subsection.3.5.3}%
\contentsline {chapter}{\numberline {4}Results}{42}{chapter.4}%
\contentsline {section}{\numberline {4.1}The effects of different components in our pipeline}{47}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Bloom vs other LLMs}{47}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Unspecified prompt style vs formal prompt style}{50}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}Effect of post-processing}{52}{subsection.4.1.3}%
\contentsline {subsection}{\numberline {4.1.4}Using different subsets of features}{55}{subsection.4.1.4}%
\contentsline {subsection}{\numberline {4.1.5}Effect of text generation parameters}{56}{subsection.4.1.5}%
\contentsline {subsection}{\numberline {4.1.6}Shots from unrelated vs related category}{58}{subsection.4.1.6}%
\contentsline {section}{\numberline {4.2}Bloom based coherence metric}{60}{section.4.2}%
\contentsline {section}{\numberline {4.3}Study: Q\&A with the bert model}{61}{section.4.3}%
\contentsline {chapter}{\numberline {5}Discussion}{63}{chapter.5}%
\contentsline {section}{\numberline {5.1}Dataset}{63}{section.5.1}%
\contentsline {section}{\numberline {5.2}Pre-processing}{65}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Qualities and Challenges of Finding Product Descriptions for using as shots}{66}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Shots from unrelated vs related category}{68}{subsection.5.2.2}%
\contentsline {subsection}{\numberline {5.2.3}Category description: with or without}{69}{subsection.5.2.3}%
\contentsline {section}{\numberline {5.3}Description generation}{69}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Bloom vs other LLMs}{69}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}Text generation in German vs English}{70}{subsection.5.3.2}%
\contentsline {subsection}{\numberline {5.3.3}Prompt style}{71}{subsection.5.3.3}%
\contentsline {subsection}{\numberline {5.3.4}Using different subsets of features}{72}{subsection.5.3.4}%
\contentsline {subsection}{\numberline {5.3.5}Using different hyper-parameters for text generation}{72}{subsection.5.3.5}%
\contentsline {section}{\numberline {5.4}Post-processing}{73}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Does rewriting actually help?}{73}{subsection.5.4.1}%
\contentsline {subsection}{\numberline {5.4.2}Hallucinations}{74}{subsection.5.4.2}%
\contentsline {section}{\numberline {5.5}Evaluation}{75}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}How reliable are the readability metrics?}{75}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}Why do we use flesh reading ease instead of other readability metrics?}{76}{subsection.5.5.2}%
\contentsline {subsection}{\numberline {5.5.3}How reliable is the class classification metric?}{76}{subsection.5.5.3}%
\contentsline {subsection}{\numberline {5.5.4}Compound words in German and vectorization of them}{76}{subsection.5.5.4}%
\contentsline {subsection}{\numberline {5.5.5}Bloom based coherence metric}{77}{subsection.5.5.5}%
\contentsline {section}{\numberline {5.6}Time complexity}{78}{section.5.6}%
\contentsline {section}{\numberline {5.7}Future work}{78}{section.5.7}%
\contentsline {chapter}{\numberline {6}Conclusion}{81}{chapter.6}%
\contentsline {chapter}{\nonumberline Bibliography}{83}{chapter*.37}%
\contentsline {chapter}{\nonumberline Eidesstattliche Erkl\"arung}{88}{chapter*.38}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
